{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db725b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Bidirectional,TimeDistributed\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Input, Dense, LSTM, Reshape\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ac83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"AMJ\",\"XLY\",\"XLB\",\"^GSPC\",\"^DJI\",\"^IXIC\",\"^NYA\",\"^RUT\"]\n",
    "start_date = \"2018-08-19\"\n",
    "end_date = \"2023-11-01\"\n",
    "etf_data = {}\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    etf_data[ticker] = data\n",
    "\n",
    "    \n",
    "# ETF data frames\n",
    "amj_df = etf_data[\"AMJ\"]\n",
    "xly_df = etf_data[\"XLY\"]\n",
    "xlb_df = etf_data[\"XLB\"]\n",
    "\n",
    "# Index data frames\n",
    "gspc_df = etf_data[\"^GSPC\"]\n",
    "dji_df = etf_data[\"^DJI\"]\n",
    "ixic_df = etf_data[\"^IXIC\"]\n",
    "nya_df = etf_data[\"^NYA\"]\n",
    "rut_df = etf_data[\"^RUT\"]\n",
    "\n",
    "# drop Volume\n",
    "amj_df = amj_df.drop('Volume', axis = 1)\n",
    "\n",
    "dji_df = dji_df.rename(columns={'Adj Close': 'DJI_Adj Close', 'Close': 'DJI_Close', 'High': 'DJI_High', 'Low': 'DJI_Low', 'Open': 'DJI_Open','Volume': 'DJI_Volume'})\n",
    "gspc_df = gspc_df.rename(columns={'Adj Close': 'GSPC_Adj Close', 'Close': 'GSPC_Close', 'High': 'GSPC_High', 'Low': 'GSPC_Low', 'Open': 'GSPC_Open','Volume': 'GSPC_Volume'})\n",
    "ixic_df = ixic_df.rename(columns={'Adj Close': 'IXIC_Adj Close', 'Close': 'IXIC_Close', 'High': 'IXIC_High', 'Low': 'IXIC_Low', 'Open': 'IXIC_Open','Volume': 'IXIC_Volume'})\n",
    "nya_df = nya_df.rename(columns={'Adj Close': 'NYA_Adj Close', 'Close': 'NYA_Close', 'High': 'NYA_High', 'Low': 'NYA_Low', 'Open': 'NYA_Open','Volume': 'NYA_Volume'})\n",
    "rut_df = rut_df.rename(columns={'Adj Close': 'RUT_Adj Close', 'Close': 'RUT_Close', 'High': 'RUT_High', 'Low': 'RUT_Low', 'Open': 'RUT_Open','Volume': 'RUT_Volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ff7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_inferences(etf_data):\n",
    "    '''\n",
    "    Function calculates all technical indicators possible like RSI, EMA, SMA. \n",
    "    Input: 1 data frame containing ETF data \n",
    "    Output: The data frame with all calculated values for the particular ETF.\n",
    "    '''\n",
    "    rsi_period = 14\n",
    "    # Calculate RSI\n",
    "    etf_data['RSI'] = ta.rsi(etf_data['Adj Close'], length=rsi_period)\n",
    "\n",
    "    # Calculate overbought/oversold conditions\n",
    "    etf_data['Overbought'] = (etf_data['RSI'] > 70).astype(int)\n",
    "    etf_data['Oversold'] = (etf_data['RSI'] < 30).astype(int)\n",
    "    \n",
    "    # Calculate divergence between price and RSI\n",
    "    etf_data['Price_RSI_Divergence'] = etf_data['Close'].diff() - etf_data['RSI'].diff()\n",
    "    \n",
    "    # Calculate rate of change of RSI\n",
    "    etf_data['ROC_RSI'] = etf_data['RSI'].pct_change() * 100\n",
    "    \n",
    "    # Calculate RSI trend confirmation\n",
    "    etf_data['RSI_Trend_Confirmation'] = (etf_data['RSI'] > etf_data['RSI'].shift(1)).astype(int)\n",
    "    \n",
    "    # Assuming 'Close' is the column containing closing prices\n",
    "    etf_data['EMA'] = ta.ema(etf_data['Close'], length=14)  # Adjust the period as needed\n",
    "    \n",
    "    # Feature 1: EMA over a specific period\n",
    "    # Already calculated and stored in 'EMA' column\n",
    "    \n",
    "    # Feature 2: Difference between current price and EMA\n",
    "    etf_data['Price_EMA_Difference'] = etf_data['Close'] - etf_data['EMA']\n",
    "    \n",
    "    # Feature 3: Slope of EMA\n",
    "    etf_data['Slope_EMA'] = ta.slope(etf_data['EMA'])\n",
    "    \n",
    "    # Feature 4: EMA convergence or divergence\n",
    "    etf_data['EMA_Convergence'] = (etf_data['Close'] > etf_data['EMA']).astype(int)\n",
    "    etf_data['EMA_Divergence'] = (etf_data['Close'] < etf_data['EMA']).astype(int)\n",
    "    \n",
    "    # Feature 5: Rate of change of EMA\n",
    "    etf_data['ROC_EMA'] = etf_data['EMA'].pct_change() * 100\n",
    "    \n",
    "    # Assuming 'Close' is the column containing closing prices\n",
    "    etf_data['SMA'] = ta.sma(etf_data['Close'], length=14)  # Adjust the period as needed\n",
    "    \n",
    "    # Feature 1: SMA over a specific period\n",
    "    # Already calculated and stored in 'SMA' column\n",
    "    \n",
    "    # Feature 2: Difference between current price and SMA\n",
    "    etf_data['Price_SMA_Difference'] = etf_data['Close'] - etf_data['SMA']\n",
    "    \n",
    "    # Feature 3: Slope of SMA\n",
    "    etf_data['Slope_SMA'] = ta.slope(etf_data['SMA'])\n",
    "    \n",
    "    # Feature 4: SMA convergence or divergence\n",
    "    etf_data['SMA_Convergence'] = (etf_data['Close'] > etf_data['SMA']).astype(int)\n",
    "    etf_data['SMA_Divergence'] = (etf_data['Close'] < etf_data['SMA']).astype(int)\n",
    "    \n",
    "    # Feature 5: Rate of change of SMA\n",
    "    etf_data['ROC_SMA'] = etf_data['SMA'].pct_change() * 100\n",
    "    \n",
    "    dmi = ta.adx(etf_data.High, etf_data.Low, etf_data.Close)\n",
    "    etf_data['ADX']=dmi['ADX_14']\n",
    "    etf_data['DMI+']=dmi['DMP_14']\n",
    "    etf_data['DMI-']=dmi['DMN_14']\n",
    "    # Calculate ADX trend strength\n",
    "    etf_data['ADX_Trend_Strength'] = etf_data['ADX'].rolling(window=3).mean()  # Adjust the rolling window parameter\n",
    "    \n",
    "    # Calculate DI convergence or divergence\n",
    "    etf_data['DI_Convergence_Divergence'] = etf_data['DMI+'] - etf_data['DMI-']  # Adjust the length parameter\n",
    "    return etf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5fa7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_for_model(etf_data):\n",
    "    '''\n",
    "    Function calculates all technical indicators possible like RSI, EMA, SMA. \n",
    "    Input: 1 data frame containing ETF data \n",
    "    Output: The data frame with all calculated values for the particular ETF.\n",
    "    '''\n",
    "    rsi_period = 14\n",
    "    # Calculate RSI\n",
    "    etf_data['RSI'] = ta.rsi(etf_data['Adj Close'], length=rsi_period)\n",
    "\n",
    "    # Calculate overbought/oversold conditions\n",
    "    etf_data['Overbought'] = (etf_data['RSI'] > 70).astype(int)\n",
    "    etf_data['Oversold'] = (etf_data['RSI'] < 30).astype(int)\n",
    "    \n",
    "    # Calculate divergence between price and RSI\n",
    "    etf_data['Price_RSI_Divergence'] = etf_data['Close'].diff() - etf_data['RSI'].diff()\n",
    "    \n",
    "    # Calculate rate of change of RSI\n",
    "    etf_data['ROC_RSI'] = etf_data['RSI'].pct_change() * 100\n",
    "    \n",
    "    # Calculate RSI trend confirmation\n",
    "    etf_data['RSI_Trend_Confirmation'] = (etf_data['RSI'] > etf_data['RSI'].shift(1)).astype(int)\n",
    "    \n",
    "    # Assuming 'Close' is the column containing closing prices\n",
    "    etf_data['EMA'] = ta.ema(etf_data['Close'], length=14)  # Adjust the period as needed\n",
    "    \n",
    "    # Feature 1: EMA over a specific period\n",
    "    # Already calculated and stored in 'EMA' column\n",
    "    \n",
    "    # Feature 2: Difference between current price and EMA\n",
    "    etf_data['Price_EMA_Difference'] = etf_data['Close'] - etf_data['EMA']\n",
    "    \n",
    "    # Feature 3: Slope of EMA\n",
    "    etf_data['Slope_EMA'] = ta.slope(etf_data['EMA'])\n",
    "    \n",
    "    # Feature 4: EMA convergence or divergence\n",
    "    etf_data['EMA_Convergence'] = (etf_data['Close'] > etf_data['EMA']).astype(int)\n",
    "    etf_data['EMA_Divergence'] = (etf_data['Close'] < etf_data['EMA']).astype(int)\n",
    "    \n",
    "    # Feature 5: Rate of change of EMA\n",
    "    etf_data['ROC_EMA'] = etf_data['EMA'].pct_change() * 100\n",
    "    \n",
    "    # Assuming 'Close' is the column containing closing prices\n",
    "    etf_data['SMA'] = ta.sma(etf_data['Close'], length=14)  # Adjust the period as needed\n",
    "    \n",
    "    # Feature 1: SMA over a specific period\n",
    "    # Already calculated and stored in 'SMA' column\n",
    "    \n",
    "    # Feature 2: Difference between current price and SMA\n",
    "    etf_data['Price_SMA_Difference'] = etf_data['Close'] - etf_data['SMA']\n",
    "    \n",
    "    # Feature 3: Slope of SMA\n",
    "    etf_data['Slope_SMA'] = ta.slope(etf_data['SMA'])\n",
    "    \n",
    "    # Feature 4: SMA convergence or divergence\n",
    "    etf_data['SMA_Convergence'] = (etf_data['Close'] > etf_data['SMA']).astype(int)\n",
    "    etf_data['SMA_Divergence'] = (etf_data['Close'] < etf_data['SMA']).astype(int)\n",
    "    \n",
    "    # Feature 5: Rate of change of SMA\n",
    "    etf_data['ROC_SMA'] = etf_data['SMA'].pct_change() * 100\n",
    "    \n",
    "    dmi = ta.adx(etf_data.High, etf_data.Low, etf_data.Close)\n",
    "    etf_data['ADX']=dmi['ADX_14']\n",
    "    etf_data['DMI+']=dmi['DMP_14']\n",
    "    etf_data['DMI-']=dmi['DMN_14']\n",
    "    # Calculate ADX trend strength\n",
    "    etf_data['ADX_Trend_Strength'] = etf_data['ADX'].rolling(window=3).mean()  # Adjust the rolling window parameter\n",
    "    \n",
    "    # Calculate DI convergence or divergence\n",
    "    etf_data['DI_Convergence_Divergence'] = etf_data['DMI+'] - etf_data['DMI-']  # Adjust the length parameter\n",
    "    return etf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50fc1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call for calculating technical indicators\n",
    "amj_df = analytical_inferences(amj_df)\n",
    "xly_df = analytical_inferences(xly_df)\n",
    "xlb_df = analytical_inferences(xlb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c138931",
   "metadata": {},
   "outputs": [],
   "source": [
    "amj_df_stats = stats_for_model(amj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8743fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stock_index_data(stock_data, dji_df, gspc_df, ixic_df, nya_df, rut_df):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df = pd.DataFrame(reduce(lambda left, right: pd.merge(left, right, on='Date', how='outer'), [stock_data, dji_df, gspc_df, ixic_df, nya_df, rut_df]))\n",
    "    new_df = new_df.dropna()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49798c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the stock data with index data\n",
    "amj_combined_df = merge_stock_index_data(amj_df, dji_df, gspc_df, ixic_df, nya_df, rut_df)\n",
    "xly_combined_df = merge_stock_index_data(xly_df, dji_df, gspc_df, ixic_df, nya_df, rut_df)\n",
    "xlb_combined_df = merge_stock_index_data(xlb_df, dji_df, gspc_df, ixic_df, nya_df, rut_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a56e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation_for_dbn(stock_data):\n",
    "    '''\n",
    "    The function prepares data for the models defined below. \n",
    "    This function manipulates the data so that the model inputs previous day's data to predict return for current day.\n",
    "    Input: Data frame with all features required for regression.\n",
    "    Output: Manipulated Data frame\n",
    "    '''\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df = stock_data.shift(1)\n",
    "    new_df = new_df.dropna()\n",
    "    new_df = pd.merge(stock_data['Adj Close'], new_df, on = 'Date', how='inner')\n",
    "    new_df = new_df.rename(columns={'Adj Close_x': 'Curr Adj Close', 'Adj Close_y': 'Prev Adj Close'})\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af3f09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Call for data preparation\n",
    "amj_manipulated_data = data_preparation_for_dbn(amj_df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0530640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(data):\n",
    "    X = data.drop('Curr Adj Close', axis =1)\n",
    "    y = data['Curr Adj Close']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    return X, y, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a520fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation_model2(data):\n",
    "    X = data.drop(data.iloc[:, 5:], axis = 1)\n",
    "    y = data.iloc[:, :4].copy()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    return X, y, X_train, X_test, y_train, y_test,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f4f6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df = amj_manipulated_data.iloc[:, :5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b1b1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df=model2_df.rename(columns={'Open': 'Prev Open', 'High': 'Prev High', 'Low': 'Prev Low', 'Close': 'Prev Close'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c36b6d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curr Adj Close</th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>18.611868</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.139999</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-03</th>\n",
       "      <td>18.745193</td>\n",
       "      <td>28.059999</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>27.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>18.605204</td>\n",
       "      <td>27.950001</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-05</th>\n",
       "      <td>18.631866</td>\n",
       "      <td>28.070000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>27.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-08</th>\n",
       "      <td>18.558535</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>24.509180</td>\n",
       "      <td>24.820000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>24.809999</td>\n",
       "      <td>24.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>24.342049</td>\n",
       "      <td>25.049999</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>24.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>24.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.719999</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>24.342049</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Curr Adj Close  Prev Open  Prev High   Prev Low  Prev Close\n",
       "Date                                                                   \n",
       "2018-10-02       18.611868  27.520000  28.139999  27.520000   28.049999\n",
       "2018-10-03       18.745193  28.059999  28.150000  27.860001   27.920000\n",
       "2018-10-04       18.605204  27.950001  28.250000  27.900000   28.120001\n",
       "2018-10-05       18.631866  28.070000  28.120001  27.870001   27.910000\n",
       "2018-10-08       18.558535  27.820000  28.190001  27.809999   27.950001\n",
       "...                    ...        ...        ...        ...         ...\n",
       "2023-10-25       24.509180  24.820000  24.990000  24.809999   24.959999\n",
       "2023-10-26       24.342049  25.049999  25.059999  24.870001   24.930000\n",
       "2023-10-27       24.155256  24.889999  24.889999  24.650000   24.760000\n",
       "2023-10-30       24.155256  24.700001  24.719999  24.500000   24.570000\n",
       "2023-10-31       24.342049  24.510000  24.700001  24.379999   24.570000\n",
       "\n",
       "[1279 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3823e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Curr Adj Close</th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>28.059999</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>27.920000</td>\n",
       "      <td>18.611868</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.139999</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-03</th>\n",
       "      <td>27.950001</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>18.745193</td>\n",
       "      <td>28.059999</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>27.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>28.070000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>27.910000</td>\n",
       "      <td>18.605204</td>\n",
       "      <td>27.950001</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-05</th>\n",
       "      <td>27.820000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.950001</td>\n",
       "      <td>18.631866</td>\n",
       "      <td>28.070000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>27.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-08</th>\n",
       "      <td>27.809999</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>27.680000</td>\n",
       "      <td>27.840000</td>\n",
       "      <td>18.558535</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>25.049999</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>24.509180</td>\n",
       "      <td>24.820000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>24.809999</td>\n",
       "      <td>24.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>24.760000</td>\n",
       "      <td>24.342049</td>\n",
       "      <td>25.049999</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>24.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.719999</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.570000</td>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>24.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.719999</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>24.530001</td>\n",
       "      <td>24.840000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.760000</td>\n",
       "      <td>24.342049</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Curr Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-10-02  28.059999  28.150000  27.860001  27.920000       18.611868   \n",
       "2018-10-03  27.950001  28.250000  27.900000  28.120001       18.745193   \n",
       "2018-10-04  28.070000  28.120001  27.870001  27.910000       18.605204   \n",
       "2018-10-05  27.820000  28.190001  27.809999  27.950001       18.631866   \n",
       "2018-10-08  27.809999  28.049999  27.680000  27.840000       18.558535   \n",
       "...               ...        ...        ...        ...             ...   \n",
       "2023-10-25  25.049999  25.059999  24.870001  24.930000       24.509180   \n",
       "2023-10-26  24.889999  24.889999  24.650000  24.760000       24.342049   \n",
       "2023-10-27  24.700001  24.719999  24.500000  24.570000       24.155256   \n",
       "2023-10-30  24.510000  24.700001  24.379999  24.570000       24.155256   \n",
       "2023-10-31  24.530001  24.840000  24.500000  24.760000       24.342049   \n",
       "\n",
       "            Prev Open  Prev High   Prev Low  Prev Close  \n",
       "Date                                                     \n",
       "2018-10-02  27.520000  28.139999  27.520000   28.049999  \n",
       "2018-10-03  28.059999  28.150000  27.860001   27.920000  \n",
       "2018-10-04  27.950001  28.250000  27.900000   28.120001  \n",
       "2018-10-05  28.070000  28.120001  27.870001   27.910000  \n",
       "2018-10-08  27.820000  28.190001  27.809999   27.950001  \n",
       "...               ...        ...        ...         ...  \n",
       "2023-10-25  24.820000  24.990000  24.809999   24.959999  \n",
       "2023-10-26  25.049999  25.059999  24.870001   24.930000  \n",
       "2023-10-27  24.889999  24.889999  24.650000   24.760000  \n",
       "2023-10-30  24.700001  24.719999  24.500000   24.570000  \n",
       "2023-10-31  24.510000  24.700001  24.379999   24.570000  \n",
       "\n",
       "[1279 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_df = pd.merge(amj_combined_df.iloc[:, :5], model2_df, on = 'Date', how='inner')\n",
    "#model2_df = model2_df.drop(['Adj Close'],axis=1)\n",
    "model2_df = model2_df.drop(['Adj Close'],axis=1)\n",
    "model2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd81847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_df = model2_df.rename(columns={'Open': 'Curr Open', 'High': 'Curr High', 'Low': 'Curr Low', 'Close': 'Curr Close'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2339dfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curr Open</th>\n",
       "      <th>Curr High</th>\n",
       "      <th>Curr Low</th>\n",
       "      <th>Curr Close</th>\n",
       "      <th>Curr Adj Close</th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>28.059999</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>27.920000</td>\n",
       "      <td>18.611868</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.139999</td>\n",
       "      <td>27.520000</td>\n",
       "      <td>28.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-03</th>\n",
       "      <td>27.950001</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>18.745193</td>\n",
       "      <td>28.059999</td>\n",
       "      <td>28.150000</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>27.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>28.070000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>27.910000</td>\n",
       "      <td>18.605204</td>\n",
       "      <td>27.950001</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>28.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-05</th>\n",
       "      <td>27.820000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.950001</td>\n",
       "      <td>18.631866</td>\n",
       "      <td>28.070000</td>\n",
       "      <td>28.120001</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>27.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-08</th>\n",
       "      <td>27.809999</td>\n",
       "      <td>28.049999</td>\n",
       "      <td>27.680000</td>\n",
       "      <td>27.840000</td>\n",
       "      <td>18.558535</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>28.190001</td>\n",
       "      <td>27.809999</td>\n",
       "      <td>27.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-25</th>\n",
       "      <td>25.049999</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>24.930000</td>\n",
       "      <td>24.509180</td>\n",
       "      <td>24.820000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>24.809999</td>\n",
       "      <td>24.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-26</th>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>24.760000</td>\n",
       "      <td>24.342049</td>\n",
       "      <td>25.049999</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>24.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-27</th>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.719999</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.570000</td>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>24.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-30</th>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "      <td>24.155256</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.719999</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>24.530001</td>\n",
       "      <td>24.840000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.760000</td>\n",
       "      <td>24.342049</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Curr Open  Curr High   Curr Low  Curr Close  Curr Adj Close  \\\n",
       "Date                                                                      \n",
       "2018-10-02  28.059999  28.150000  27.860001   27.920000       18.611868   \n",
       "2018-10-03  27.950001  28.250000  27.900000   28.120001       18.745193   \n",
       "2018-10-04  28.070000  28.120001  27.870001   27.910000       18.605204   \n",
       "2018-10-05  27.820000  28.190001  27.809999   27.950001       18.631866   \n",
       "2018-10-08  27.809999  28.049999  27.680000   27.840000       18.558535   \n",
       "...               ...        ...        ...         ...             ...   \n",
       "2023-10-25  25.049999  25.059999  24.870001   24.930000       24.509180   \n",
       "2023-10-26  24.889999  24.889999  24.650000   24.760000       24.342049   \n",
       "2023-10-27  24.700001  24.719999  24.500000   24.570000       24.155256   \n",
       "2023-10-30  24.510000  24.700001  24.379999   24.570000       24.155256   \n",
       "2023-10-31  24.530001  24.840000  24.500000   24.760000       24.342049   \n",
       "\n",
       "            Prev Open  Prev High   Prev Low  Prev Close  \n",
       "Date                                                     \n",
       "2018-10-02  27.520000  28.139999  27.520000   28.049999  \n",
       "2018-10-03  28.059999  28.150000  27.860001   27.920000  \n",
       "2018-10-04  27.950001  28.250000  27.900000   28.120001  \n",
       "2018-10-05  28.070000  28.120001  27.870001   27.910000  \n",
       "2018-10-08  27.820000  28.190001  27.809999   27.950001  \n",
       "...               ...        ...        ...         ...  \n",
       "2023-10-25  24.820000  24.990000  24.809999   24.959999  \n",
       "2023-10-26  25.049999  25.059999  24.870001   24.930000  \n",
       "2023-10-27  24.889999  24.889999  24.650000   24.760000  \n",
       "2023-10-30  24.700001  24.719999  24.500000   24.570000  \n",
       "2023-10-31  24.510000  24.700001  24.379999   24.570000  \n",
       "\n",
       "[1279 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc85ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 4ms/step - loss: 228.6480\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 23.5052\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 5.9507\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.6761\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.7972\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.5345\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2473\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1116\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7600\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5542\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 1.2244\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9351\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6599\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4137\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2817\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1684\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1317\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1178\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1057\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1107\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1115\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1098\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1026\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1037\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0966\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0974\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0911\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.1123\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0971\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0897\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0856\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0943\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0882\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0922\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0926\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0879\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0933\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0904\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0952\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0954\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0892\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0874\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0812\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0833\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0805\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0895\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1086\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "32/32 - 3s - loss: 32.6171 - val_loss: 0.4906 - 3s/epoch - 83ms/step\n",
      "Epoch 2/50\n",
      "32/32 - 0s - loss: 0.2229 - val_loss: 0.0652 - 181ms/epoch - 6ms/step\n",
      "Epoch 3/50\n",
      "32/32 - 0s - loss: 0.0821 - val_loss: 0.0662 - 153ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "32/32 - 0s - loss: 0.0788 - val_loss: 0.0655 - 157ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "32/32 - 0s - loss: 0.0783 - val_loss: 0.0632 - 167ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "32/32 - 0s - loss: 0.0778 - val_loss: 0.0625 - 179ms/epoch - 6ms/step\n",
      "Epoch 7/50\n",
      "32/32 - 0s - loss: 0.0774 - val_loss: 0.0636 - 166ms/epoch - 5ms/step\n",
      "Epoch 8/50\n",
      "32/32 - 0s - loss: 0.0771 - val_loss: 0.0622 - 156ms/epoch - 5ms/step\n",
      "Epoch 9/50\n",
      "32/32 - 0s - loss: 0.0775 - val_loss: 0.0622 - 160ms/epoch - 5ms/step\n",
      "Epoch 10/50\n",
      "32/32 - 0s - loss: 0.0780 - val_loss: 0.0626 - 143ms/epoch - 4ms/step\n",
      "Epoch 11/50\n",
      "32/32 - 0s - loss: 0.0769 - val_loss: 0.0622 - 158ms/epoch - 5ms/step\n",
      "Epoch 12/50\n",
      "32/32 - 0s - loss: 0.0776 - val_loss: 0.0635 - 141ms/epoch - 4ms/step\n",
      "Epoch 13/50\n",
      "32/32 - 0s - loss: 0.0777 - val_loss: 0.0630 - 149ms/epoch - 5ms/step\n",
      "Epoch 14/50\n",
      "32/32 - 0s - loss: 0.0780 - val_loss: 0.0619 - 151ms/epoch - 5ms/step\n",
      "Epoch 15/50\n",
      "32/32 - 0s - loss: 0.0770 - val_loss: 0.0622 - 145ms/epoch - 5ms/step\n",
      "Epoch 16/50\n",
      "32/32 - 0s - loss: 0.0770 - val_loss: 0.0622 - 142ms/epoch - 4ms/step\n",
      "Epoch 17/50\n",
      "32/32 - 0s - loss: 0.0769 - val_loss: 0.0621 - 150ms/epoch - 5ms/step\n",
      "Epoch 18/50\n",
      "32/32 - 0s - loss: 0.0809 - val_loss: 0.0671 - 145ms/epoch - 5ms/step\n",
      "Epoch 19/50\n",
      "32/32 - 0s - loss: 0.0778 - val_loss: 0.0639 - 144ms/epoch - 4ms/step\n",
      "Epoch 20/50\n",
      "32/32 - 0s - loss: 0.0769 - val_loss: 0.0627 - 136ms/epoch - 4ms/step\n",
      "Epoch 21/50\n",
      "32/32 - 0s - loss: 0.0768 - val_loss: 0.0630 - 158ms/epoch - 5ms/step\n",
      "Epoch 22/50\n",
      "32/32 - 0s - loss: 0.0767 - val_loss: 0.0625 - 153ms/epoch - 5ms/step\n",
      "Epoch 23/50\n",
      "32/32 - 0s - loss: 0.0788 - val_loss: 0.0646 - 146ms/epoch - 5ms/step\n",
      "Epoch 24/50\n",
      "32/32 - 0s - loss: 0.0766 - val_loss: 0.0635 - 149ms/epoch - 5ms/step\n",
      "Epoch 25/50\n",
      "32/32 - 0s - loss: 0.0787 - val_loss: 0.0669 - 133ms/epoch - 4ms/step\n",
      "Epoch 26/50\n",
      "32/32 - 0s - loss: 0.0781 - val_loss: 0.0623 - 157ms/epoch - 5ms/step\n",
      "Epoch 27/50\n",
      "32/32 - 0s - loss: 0.0767 - val_loss: 0.0628 - 237ms/epoch - 7ms/step\n",
      "Epoch 28/50\n",
      "32/32 - 0s - loss: 0.0767 - val_loss: 0.0627 - 193ms/epoch - 6ms/step\n",
      "Epoch 29/50\n",
      "32/32 - 0s - loss: 0.0767 - val_loss: 0.0629 - 141ms/epoch - 4ms/step\n",
      "Epoch 30/50\n",
      "32/32 - 0s - loss: 0.0790 - val_loss: 0.0623 - 141ms/epoch - 4ms/step\n",
      "Epoch 31/50\n",
      "32/32 - 0s - loss: 0.0785 - val_loss: 0.0625 - 160ms/epoch - 5ms/step\n",
      "Epoch 32/50\n",
      "32/32 - 0s - loss: 0.0777 - val_loss: 0.0627 - 190ms/epoch - 6ms/step\n",
      "Epoch 33/50\n",
      "32/32 - 0s - loss: 0.0771 - val_loss: 0.0629 - 186ms/epoch - 6ms/step\n",
      "Epoch 34/50\n",
      "32/32 - 0s - loss: 0.0773 - val_loss: 0.0658 - 254ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "32/32 - 0s - loss: 0.0778 - val_loss: 0.0622 - 187ms/epoch - 6ms/step\n",
      "Epoch 36/50\n",
      "32/32 - 0s - loss: 0.0766 - val_loss: 0.0623 - 159ms/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "32/32 - 0s - loss: 0.0769 - val_loss: 0.0627 - 214ms/epoch - 7ms/step\n",
      "Epoch 38/50\n",
      "32/32 - 0s - loss: 0.0780 - val_loss: 0.0624 - 144ms/epoch - 5ms/step\n",
      "Epoch 39/50\n",
      "32/32 - 0s - loss: 0.0791 - val_loss: 0.0634 - 168ms/epoch - 5ms/step\n",
      "Epoch 40/50\n",
      "32/32 - 0s - loss: 0.0799 - val_loss: 0.0640 - 196ms/epoch - 6ms/step\n",
      "Epoch 41/50\n",
      "32/32 - 0s - loss: 0.0792 - val_loss: 0.0690 - 151ms/epoch - 5ms/step\n",
      "Epoch 42/50\n",
      "32/32 - 0s - loss: 0.0787 - val_loss: 0.0627 - 159ms/epoch - 5ms/step\n",
      "Epoch 43/50\n",
      "32/32 - 0s - loss: 0.0791 - val_loss: 0.0666 - 139ms/epoch - 4ms/step\n",
      "Epoch 44/50\n",
      "32/32 - 0s - loss: 0.0815 - val_loss: 0.0670 - 166ms/epoch - 5ms/step\n",
      "Epoch 45/50\n",
      "32/32 - 0s - loss: 0.0778 - val_loss: 0.0631 - 182ms/epoch - 6ms/step\n",
      "Epoch 46/50\n",
      "32/32 - 0s - loss: 0.0774 - val_loss: 0.0623 - 172ms/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "32/32 - 0s - loss: 0.0780 - val_loss: 0.0633 - 149ms/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "32/32 - 0s - loss: 0.0770 - val_loss: 0.0629 - 169ms/epoch - 5ms/step\n",
      "Epoch 49/50\n",
      "32/32 - 0s - loss: 0.0765 - val_loss: 0.0623 - 219ms/epoch - 7ms/step\n",
      "Epoch 50/50\n",
      "32/32 - 0s - loss: 0.0790 - val_loss: 0.0789 - 159ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b972fad350>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################### DBN Begins here to predict Adj Close ###################################################\n",
    "X, y, *_ = data_transformation(amj_manipulated_data)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "dbn_input = Input(shape=(scaled_features.shape[1],))\n",
    "x = Dense(units=100, activation='relu')(dbn_input)\n",
    "x = Dense(units=80, activation='relu')(x)\n",
    "x = Dense(units=60, activation='relu')(x)\n",
    "dbn_output = Dense(units=20, activation='linear')(x)\n",
    "dbn_model = Model(inputs=dbn_input, outputs=dbn_output)\n",
    "dbn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the DBN model\n",
    "dbn_model.fit(scaled_features, y, epochs=50, batch_size=32)\n",
    "\n",
    "dbn_output = dbn_model.predict(scaled_features)\n",
    "n_samples, n_features = dbn_output.shape\n",
    "n_timesteps = 1\n",
    "dbn_output_reshaped = dbn_output.reshape((n_samples, n_timesteps, n_features))\n",
    "lstm_input = Input(shape=(n_timesteps, n_features))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dbn_output_reshaped,y, test_size=0.2, random_state=42)\n",
    "######################################## LSTM begins here to predict Adj Close ###################################################\n",
    "x = LSTM(50, activation='relu')(lstm_input)\n",
    "lstm_output = Dense(1)(x)  # Output layer with one neuron for regression\n",
    "lstm_model = Model(inputs=lstm_input, outputs=lstm_output)\n",
    "lstm_model.compile(optimizer='adam', loss='mse')  # Mean Squared Error (MSE) loss for regression\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63309129",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,*_,X_scaled = data_transformation_model2(model2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d02f03aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 6ms/step - loss: 371.7690\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 80.0958\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.3621\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6346\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3155\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1057\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0614\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0452\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0290\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0244\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0219\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0175\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0170\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "32/32 - 4s - loss: 346.5530 - val_loss: 273.9155 - 4s/epoch - 113ms/step\n",
      "Epoch 2/50\n",
      "32/32 - 0s - loss: 174.8647 - val_loss: 75.2781 - 185ms/epoch - 6ms/step\n",
      "Epoch 3/50\n",
      "32/32 - 0s - loss: 29.9017 - val_loss: 8.7150 - 185ms/epoch - 6ms/step\n",
      "Epoch 4/50\n",
      "32/32 - 0s - loss: 3.4757 - val_loss: 0.7556 - 180ms/epoch - 6ms/step\n",
      "Epoch 5/50\n",
      "32/32 - 0s - loss: 0.3082 - val_loss: 0.1168 - 189ms/epoch - 6ms/step\n",
      "Epoch 6/50\n",
      "32/32 - 0s - loss: 0.1123 - val_loss: 0.0985 - 180ms/epoch - 6ms/step\n",
      "Epoch 7/50\n",
      "32/32 - 0s - loss: 0.1037 - val_loss: 0.0924 - 213ms/epoch - 7ms/step\n",
      "Epoch 8/50\n",
      "32/32 - 0s - loss: 0.0969 - val_loss: 0.0864 - 189ms/epoch - 6ms/step\n",
      "Epoch 9/50\n",
      "32/32 - 0s - loss: 0.0907 - val_loss: 0.0808 - 200ms/epoch - 6ms/step\n",
      "Epoch 10/50\n",
      "32/32 - 0s - loss: 0.0843 - val_loss: 0.0750 - 185ms/epoch - 6ms/step\n",
      "Epoch 11/50\n",
      "32/32 - 0s - loss: 0.0785 - val_loss: 0.0700 - 185ms/epoch - 6ms/step\n",
      "Epoch 12/50\n",
      "32/32 - 0s - loss: 0.0726 - val_loss: 0.0647 - 220ms/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "32/32 - 0s - loss: 0.0674 - val_loss: 0.0602 - 200ms/epoch - 6ms/step\n",
      "Epoch 14/50\n",
      "32/32 - 0s - loss: 0.0628 - val_loss: 0.0563 - 176ms/epoch - 5ms/step\n",
      "Epoch 15/50\n",
      "32/32 - 0s - loss: 0.0587 - val_loss: 0.0526 - 190ms/epoch - 6ms/step\n",
      "Epoch 16/50\n",
      "32/32 - 0s - loss: 0.0550 - val_loss: 0.0495 - 168ms/epoch - 5ms/step\n",
      "Epoch 17/50\n",
      "32/32 - 0s - loss: 0.0518 - val_loss: 0.0468 - 149ms/epoch - 5ms/step\n",
      "Epoch 18/50\n",
      "32/32 - 0s - loss: 0.0491 - val_loss: 0.0447 - 152ms/epoch - 5ms/step\n",
      "Epoch 19/50\n",
      "32/32 - 0s - loss: 0.0467 - val_loss: 0.0426 - 151ms/epoch - 5ms/step\n",
      "Epoch 20/50\n",
      "32/32 - 0s - loss: 0.0447 - val_loss: 0.0407 - 165ms/epoch - 5ms/step\n",
      "Epoch 21/50\n",
      "32/32 - 0s - loss: 0.0430 - val_loss: 0.0393 - 199ms/epoch - 6ms/step\n",
      "Epoch 22/50\n",
      "32/32 - 0s - loss: 0.0415 - val_loss: 0.0381 - 199ms/epoch - 6ms/step\n",
      "Epoch 23/50\n",
      "32/32 - 0s - loss: 0.0402 - val_loss: 0.0370 - 203ms/epoch - 6ms/step\n",
      "Epoch 24/50\n",
      "32/32 - 0s - loss: 0.0391 - val_loss: 0.0361 - 173ms/epoch - 5ms/step\n",
      "Epoch 25/50\n",
      "32/32 - 0s - loss: 0.0382 - val_loss: 0.0351 - 168ms/epoch - 5ms/step\n",
      "Epoch 26/50\n",
      "32/32 - 0s - loss: 0.0373 - val_loss: 0.0346 - 189ms/epoch - 6ms/step\n",
      "Epoch 27/50\n",
      "32/32 - 0s - loss: 0.0366 - val_loss: 0.0338 - 150ms/epoch - 5ms/step\n",
      "Epoch 28/50\n",
      "32/32 - 0s - loss: 0.0360 - val_loss: 0.0332 - 214ms/epoch - 7ms/step\n",
      "Epoch 29/50\n",
      "32/32 - 0s - loss: 0.0353 - val_loss: 0.0327 - 153ms/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "32/32 - 0s - loss: 0.0348 - val_loss: 0.0323 - 167ms/epoch - 5ms/step\n",
      "Epoch 31/50\n",
      "32/32 - 0s - loss: 0.0344 - val_loss: 0.0319 - 181ms/epoch - 6ms/step\n",
      "Epoch 32/50\n",
      "32/32 - 0s - loss: 0.0339 - val_loss: 0.0315 - 146ms/epoch - 5ms/step\n",
      "Epoch 33/50\n",
      "32/32 - 0s - loss: 0.0335 - val_loss: 0.0311 - 216ms/epoch - 7ms/step\n",
      "Epoch 34/50\n",
      "32/32 - 0s - loss: 0.0331 - val_loss: 0.0308 - 164ms/epoch - 5ms/step\n",
      "Epoch 35/50\n",
      "32/32 - 0s - loss: 0.0327 - val_loss: 0.0304 - 158ms/epoch - 5ms/step\n",
      "Epoch 36/50\n",
      "32/32 - 0s - loss: 0.0324 - val_loss: 0.0302 - 149ms/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "32/32 - 0s - loss: 0.0320 - val_loss: 0.0298 - 173ms/epoch - 5ms/step\n",
      "Epoch 38/50\n",
      "32/32 - 0s - loss: 0.0318 - val_loss: 0.0295 - 179ms/epoch - 6ms/step\n",
      "Epoch 39/50\n",
      "32/32 - 0s - loss: 0.0314 - val_loss: 0.0293 - 152ms/epoch - 5ms/step\n",
      "Epoch 40/50\n",
      "32/32 - 0s - loss: 0.0312 - val_loss: 0.0292 - 156ms/epoch - 5ms/step\n",
      "Epoch 41/50\n",
      "32/32 - 0s - loss: 0.0309 - val_loss: 0.0288 - 170ms/epoch - 5ms/step\n",
      "Epoch 42/50\n",
      "32/32 - 0s - loss: 0.0306 - val_loss: 0.0286 - 241ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "32/32 - 0s - loss: 0.0303 - val_loss: 0.0284 - 214ms/epoch - 7ms/step\n",
      "Epoch 44/50\n",
      "32/32 - 0s - loss: 0.0301 - val_loss: 0.0281 - 222ms/epoch - 7ms/step\n",
      "Epoch 45/50\n",
      "32/32 - 0s - loss: 0.0299 - val_loss: 0.0280 - 213ms/epoch - 7ms/step\n",
      "Epoch 46/50\n",
      "32/32 - 0s - loss: 0.0296 - val_loss: 0.0277 - 214ms/epoch - 7ms/step\n",
      "Epoch 47/50\n",
      "32/32 - 0s - loss: 0.0294 - val_loss: 0.0275 - 221ms/epoch - 7ms/step\n",
      "Epoch 48/50\n",
      "32/32 - 0s - loss: 0.0292 - val_loss: 0.0274 - 207ms/epoch - 6ms/step\n",
      "Epoch 49/50\n",
      "32/32 - 0s - loss: 0.0289 - val_loss: 0.0275 - 226ms/epoch - 7ms/step\n",
      "Epoch 50/50\n",
      "32/32 - 0s - loss: 0.0287 - val_loss: 0.0272 - 211ms/epoch - 7ms/step\n",
      "Mean Squared Error on test set: 0.02716229297220707\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "####################################### DBN Begins here to predict OHLC #############################\n",
    "scaler_2 = MinMaxScaler()\n",
    "X_scaled_2 = scaler_2.fit_transform(X)\n",
    "# Define and train the DBN model\n",
    "dbn_model_2 = Sequential()\n",
    "dbn_model_2.add(Dense(units=100, activation='relu', input_dim=X_scaled_2.shape[1]))\n",
    "dbn_model_2.add(Dense(units=80, activation='relu'))\n",
    "dbn_model_2.add(Dense(units=60, activation='relu'))\n",
    "dbn_model_2.add(Dense(units=4, activation='linear'))  # Output layer with 20 neurons\n",
    "dbn_model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the DBN model\n",
    "dbn_model_2.fit(X_scaled_2, y, epochs=50, batch_size=32)\n",
    "\n",
    "# Get the output of the DBN as the input for LSTM\n",
    "dbn_output_2 = dbn_model_2.predict(X_scaled_2)\n",
    "\n",
    "# Reshape the features for LSTM input (assuming a time series structure)\n",
    "n_samples, n_features = dbn_output_2.shape\n",
    "n_timesteps=1\n",
    "dbn_output_reshaped_2 = dbn_output_2.reshape((n_samples, n_timesteps, n_features))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dbn_output_reshaped_2, y, test_size=0.2, random_state=42)\n",
    "\n",
    " ######################################## LSTM begins here to predict Adj Close ###################################################\n",
    "lstm_model_2 = Sequential()\n",
    "lstm_model_2.add(LSTM(50, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "lstm_model_2.add(Dense(4))  # Output layer with one neuron for regression\n",
    "lstm_model_2.compile(optimizer='adam', loss='mse')  # Mean Squared Error (MSE) loss for regression\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model_2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "mse = lstm_model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Mean Squared Error on test set: {mse}')\n",
    "\n",
    "# Make predictions using the LSTM model\n",
    "predictions = lstm_model_2.predict(X_test)\n",
    "\n",
    "# Convert predictions back to the original scale\n",
    "#predicted_prices = scaler.inverse_transform(np.concatenate([X_test.reshape(-1, n_features)[:, :-1], predictions], axis=1))[:, -1]\n",
    "predicted_prices=predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b4afa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate dates:\n",
    "def generate_dates(year):\n",
    "    # Generate a list of dates for the given year\n",
    "    dates = pd.date_range(f'11-01-{year}', f'10-31-{year+1}', freq='D')\n",
    "    \n",
    "    # Convert the list of dates into a DataFrame\n",
    "    dates_df = pd.DataFrame(dates, columns=['Date'])\n",
    "    \n",
    "    return dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e123d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adj_close(temp_input_prep):\n",
    "    \n",
    "    scaled_new_features = scaler.transform(temp_input_prep.drop('Curr Adj Close', axis =1))\n",
    "\n",
    "    # Get the output of the DBN model\n",
    "    dbn_new_output = dbn_model.predict(scaled_new_features)\n",
    "    \n",
    "    # Reshape the features for LSTM input\n",
    "    n_samples, n_features = dbn_new_output.shape\n",
    "    n_timesteps = 1\n",
    "    dbn_new_output_reshaped = dbn_new_output.reshape((n_samples, n_timesteps, n_features))\n",
    "    \n",
    "    # Make predictions using the LSTM model\n",
    "    new_predictions = lstm_model.predict(dbn_new_output_reshaped)\n",
    "    return new_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20838c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_OHLC(temp_input_prep):\n",
    "    \n",
    "    scaled_new_features = scaler_2.transform(temp_input_prep)\n",
    "\n",
    "    # Get the output of the DBN model\n",
    "    dbn_new_output = dbn_model_2.predict(scaled_new_features)\n",
    "    \n",
    "    # Reshape the features for LSTM input\n",
    "    n_samples, n_features = dbn_new_output.shape\n",
    "    n_timesteps = 1\n",
    "    dbn_new_output_reshaped = dbn_new_output.reshape((n_samples, n_timesteps, n_features))\n",
    "    \n",
    "    # Make predictions using the LSTM model\n",
    "    new_predictions = lstm_model_2.predict(dbn_new_output_reshaped)\n",
    "    return new_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff911759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  major_df['Prev O'][0] = amj_manipulated_data['Open'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Prev O'][0] = amj_manipulated_data['Open'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.510000228881836' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Prev O'][0] = amj_manipulated_data['Open'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  major_df['Prev H'][0] = amj_manipulated_data['High'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Prev H'][0] = amj_manipulated_data['High'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.700000762939453' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Prev H'][0] = amj_manipulated_data['High'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  major_df['Prev L'][0] = amj_manipulated_data['Low'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Prev L'][0] = amj_manipulated_data['Low'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.3799991607666' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Prev L'][0] = amj_manipulated_data['Low'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  major_df['Prev C'][0] = amj_manipulated_data['Close'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Prev C'][0] = amj_manipulated_data['Close'][-1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.56999969482422' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Prev C'][0] = amj_manipulated_data['Close'][-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Sim Adj Close'][i] = sim_adj\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[24.333868]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Sim Adj Close'][i] = sim_adj\n",
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Curr O'][i] = b[0]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.563127517700195' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Curr O'][i] = b[0]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Curr H'][i] = b[1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.76805877685547' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Curr H'][i] = b[1]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Curr L'][i] = b[2]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.34075355529785' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Curr L'][i] = b[2]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  major_df['Curr C'][i] = b[3]\n",
      "C:\\Users\\shank\\AppData\\Local\\Temp\\ipykernel_28028\\288949600.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '24.44538688659668' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  major_df['Curr C'][i] = b[3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shank\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "major_df = pd.DataFrame()\n",
    "temp_input_prep = pd.DataFrame()\n",
    "major_df['Date'] = generate_dates(2023)\n",
    "major_df['Prev O'] = 0\n",
    "major_df['Prev H'] = 0\n",
    "major_df['Prev L'] = 0\n",
    "major_df['Prev C'] = 0\n",
    "major_df['Curr O'] = 0\n",
    "major_df['Curr H'] = 0\n",
    "major_df['Curr L'] = 0\n",
    "major_df['Curr C'] = 0\n",
    "major_df['Sim Adj Close'] = 0\n",
    "\n",
    "\n",
    "major_df['Prev O'][0] = amj_manipulated_data['Open'][-1]\n",
    "major_df['Prev H'][0] = amj_manipulated_data['High'][-1]\n",
    "major_df['Prev L'][0] = amj_manipulated_data['Low'][-1]\n",
    "major_df['Prev C'][0] = amj_manipulated_data['Close'][-1]\n",
    "#\n",
    "for i in range(0,50):\n",
    "    sim_adj = predict_adj_close(amj_manipulated_data[-1:])\n",
    "    major_df['Sim Adj Close'][i] = sim_adj\n",
    "    a = [[0]*5]\n",
    "    a[0][0] = major_df['Prev O'][i]\n",
    "    a[0][1] = major_df['Prev H'][i]\n",
    "    a[0][2] = major_df['Prev L'][i]\n",
    "    a[0][3] = major_df['Prev C'][i]\n",
    "    a[0][4] = major_df['Sim Adj Close'][i]\n",
    "    b = predict_OHLC(a)\n",
    "    major_df['Curr O'][i] = b[0]\n",
    "    major_df['Curr H'][i] = b[1]\n",
    "    major_df['Curr L'][i] = b[2]\n",
    "    major_df['Curr C'][i] = b[3]\n",
    "    \n",
    "    \n",
    "    new_row = {'Open': major_df['Curr O'][i], 'High': major_df['Curr H'][i],'Low': major_df['Curr L'][i],'Close': major_df['Curr C'][i], 'Adj Close': major_df['Sim Adj Close'][i]}\n",
    "    new_index = major_df['Date'][i]\n",
    "    \n",
    "    amj_df.loc[new_index] = new_row\n",
    "    \n",
    "    manipulated_amj_df = stats_for_model(amj_df)\n",
    "    amj_manipulated_data = data_preparation_for_dbn(manipulated_amj_df)\n",
    "    \n",
    "    major_df['Prev O'][i+1] = major_df['Curr O'][i]\n",
    "    major_df['Prev H'][i+1] = major_df['Curr H'][i]\n",
    "    major_df['Prev L'][i+1] = major_df['Curr L'][i]\n",
    "    major_df['Prev C'][i+1] = major_df['Curr C'][i]\n",
    "    \n",
    "  \n",
    "    #stats_for_model(etf_data)\n",
    "    #data_preparation_for_dbn(stock_data)\n",
    "    #data_transformation(data)\n",
    "    #temp_input_prep = \n",
    "    #sim_adj_close = predict_adj_close(temp_input_prep)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61729403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Prev O</th>\n",
       "      <th>Prev H</th>\n",
       "      <th>Prev L</th>\n",
       "      <th>Prev C</th>\n",
       "      <th>Curr O</th>\n",
       "      <th>Curr H</th>\n",
       "      <th>Curr L</th>\n",
       "      <th>Curr C</th>\n",
       "      <th>Sim Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>24.379999</td>\n",
       "      <td>24.570000</td>\n",
       "      <td>24.563128</td>\n",
       "      <td>24.768059</td>\n",
       "      <td>24.340754</td>\n",
       "      <td>24.445387</td>\n",
       "      <td>24.333868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>24.563128</td>\n",
       "      <td>24.768059</td>\n",
       "      <td>24.340754</td>\n",
       "      <td>24.445387</td>\n",
       "      <td>24.564661</td>\n",
       "      <td>24.769562</td>\n",
       "      <td>24.342165</td>\n",
       "      <td>24.446774</td>\n",
       "      <td>24.594799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>24.564661</td>\n",
       "      <td>24.769562</td>\n",
       "      <td>24.342165</td>\n",
       "      <td>24.446774</td>\n",
       "      <td>24.562559</td>\n",
       "      <td>24.767447</td>\n",
       "      <td>24.340057</td>\n",
       "      <td>24.444750</td>\n",
       "      <td>24.555912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>24.562559</td>\n",
       "      <td>24.767447</td>\n",
       "      <td>24.340057</td>\n",
       "      <td>24.444750</td>\n",
       "      <td>24.611757</td>\n",
       "      <td>24.817135</td>\n",
       "      <td>24.389843</td>\n",
       "      <td>24.492489</td>\n",
       "      <td>24.931833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>24.611757</td>\n",
       "      <td>24.817135</td>\n",
       "      <td>24.389843</td>\n",
       "      <td>24.492489</td>\n",
       "      <td>24.642338</td>\n",
       "      <td>24.848045</td>\n",
       "      <td>24.420855</td>\n",
       "      <td>24.522184</td>\n",
       "      <td>24.851326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>24.642338</td>\n",
       "      <td>24.848045</td>\n",
       "      <td>24.420855</td>\n",
       "      <td>24.522184</td>\n",
       "      <td>24.747187</td>\n",
       "      <td>24.954016</td>\n",
       "      <td>24.527174</td>\n",
       "      <td>24.624062</td>\n",
       "      <td>25.307402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>24.747187</td>\n",
       "      <td>24.954016</td>\n",
       "      <td>24.527174</td>\n",
       "      <td>24.624062</td>\n",
       "      <td>24.822468</td>\n",
       "      <td>25.030117</td>\n",
       "      <td>24.603537</td>\n",
       "      <td>24.697159</td>\n",
       "      <td>25.195097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>24.822468</td>\n",
       "      <td>25.030117</td>\n",
       "      <td>24.603537</td>\n",
       "      <td>24.697159</td>\n",
       "      <td>24.983639</td>\n",
       "      <td>25.193060</td>\n",
       "      <td>24.767038</td>\n",
       "      <td>24.853722</td>\n",
       "      <td>25.747158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>24.983639</td>\n",
       "      <td>25.193060</td>\n",
       "      <td>24.767038</td>\n",
       "      <td>24.853722</td>\n",
       "      <td>25.085915</td>\n",
       "      <td>25.296484</td>\n",
       "      <td>24.870846</td>\n",
       "      <td>24.953011</td>\n",
       "      <td>25.495913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>25.085915</td>\n",
       "      <td>25.296484</td>\n",
       "      <td>24.870846</td>\n",
       "      <td>24.953011</td>\n",
       "      <td>25.270473</td>\n",
       "      <td>25.483147</td>\n",
       "      <td>25.058182</td>\n",
       "      <td>25.132259</td>\n",
       "      <td>26.044176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>25.270473</td>\n",
       "      <td>25.483147</td>\n",
       "      <td>25.058182</td>\n",
       "      <td>25.132259</td>\n",
       "      <td>25.393465</td>\n",
       "      <td>25.607576</td>\n",
       "      <td>25.183088</td>\n",
       "      <td>25.251644</td>\n",
       "      <td>25.792072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-11-12</td>\n",
       "      <td>25.393465</td>\n",
       "      <td>25.607576</td>\n",
       "      <td>25.183088</td>\n",
       "      <td>25.251644</td>\n",
       "      <td>25.588408</td>\n",
       "      <td>25.804831</td>\n",
       "      <td>25.381102</td>\n",
       "      <td>25.440937</td>\n",
       "      <td>26.293468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>25.588408</td>\n",
       "      <td>25.804831</td>\n",
       "      <td>25.381102</td>\n",
       "      <td>25.440937</td>\n",
       "      <td>25.722607</td>\n",
       "      <td>25.940651</td>\n",
       "      <td>25.517475</td>\n",
       "      <td>25.571177</td>\n",
       "      <td>26.053547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>25.722607</td>\n",
       "      <td>25.940651</td>\n",
       "      <td>25.517475</td>\n",
       "      <td>25.571177</td>\n",
       "      <td>25.921316</td>\n",
       "      <td>26.141809</td>\n",
       "      <td>25.719454</td>\n",
       "      <td>25.764082</td>\n",
       "      <td>26.519480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>25.921316</td>\n",
       "      <td>26.141809</td>\n",
       "      <td>25.719454</td>\n",
       "      <td>25.764082</td>\n",
       "      <td>26.059706</td>\n",
       "      <td>26.281940</td>\n",
       "      <td>25.860186</td>\n",
       "      <td>25.898357</td>\n",
       "      <td>26.285475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>26.059706</td>\n",
       "      <td>26.281940</td>\n",
       "      <td>25.860186</td>\n",
       "      <td>25.898357</td>\n",
       "      <td>26.256159</td>\n",
       "      <td>26.480900</td>\n",
       "      <td>26.060005</td>\n",
       "      <td>26.089025</td>\n",
       "      <td>26.717447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>26.256159</td>\n",
       "      <td>26.480900</td>\n",
       "      <td>26.060005</td>\n",
       "      <td>26.089025</td>\n",
       "      <td>26.394238</td>\n",
       "      <td>26.620777</td>\n",
       "      <td>26.200518</td>\n",
       "      <td>26.222973</td>\n",
       "      <td>26.494652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-11-18</td>\n",
       "      <td>26.394238</td>\n",
       "      <td>26.620777</td>\n",
       "      <td>26.200518</td>\n",
       "      <td>26.222973</td>\n",
       "      <td>26.586699</td>\n",
       "      <td>26.815779</td>\n",
       "      <td>26.396412</td>\n",
       "      <td>26.409721</td>\n",
       "      <td>26.906139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>26.586699</td>\n",
       "      <td>26.815779</td>\n",
       "      <td>26.396412</td>\n",
       "      <td>26.409721</td>\n",
       "      <td>26.721920</td>\n",
       "      <td>26.952816</td>\n",
       "      <td>26.534107</td>\n",
       "      <td>26.540863</td>\n",
       "      <td>26.688526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>26.721920</td>\n",
       "      <td>26.952816</td>\n",
       "      <td>26.534107</td>\n",
       "      <td>26.540863</td>\n",
       "      <td>26.913568</td>\n",
       "      <td>27.147076</td>\n",
       "      <td>26.729298</td>\n",
       "      <td>26.726774</td>\n",
       "      <td>27.111891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>26.913568</td>\n",
       "      <td>27.147076</td>\n",
       "      <td>26.729298</td>\n",
       "      <td>26.726774</td>\n",
       "      <td>27.044844</td>\n",
       "      <td>27.280170</td>\n",
       "      <td>26.863066</td>\n",
       "      <td>26.854059</td>\n",
       "      <td>26.876041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>27.044844</td>\n",
       "      <td>27.280170</td>\n",
       "      <td>26.863066</td>\n",
       "      <td>26.854059</td>\n",
       "      <td>27.235376</td>\n",
       "      <td>27.473375</td>\n",
       "      <td>27.057247</td>\n",
       "      <td>27.038845</td>\n",
       "      <td>27.315159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>27.235376</td>\n",
       "      <td>27.473375</td>\n",
       "      <td>27.057247</td>\n",
       "      <td>27.038845</td>\n",
       "      <td>27.362526</td>\n",
       "      <td>27.602337</td>\n",
       "      <td>27.186892</td>\n",
       "      <td>27.162096</td>\n",
       "      <td>27.061474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-11-24</td>\n",
       "      <td>27.362526</td>\n",
       "      <td>27.602337</td>\n",
       "      <td>27.186892</td>\n",
       "      <td>27.162096</td>\n",
       "      <td>27.551767</td>\n",
       "      <td>27.794308</td>\n",
       "      <td>27.379879</td>\n",
       "      <td>27.345583</td>\n",
       "      <td>27.516254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>27.551767</td>\n",
       "      <td>27.794308</td>\n",
       "      <td>27.379879</td>\n",
       "      <td>27.345583</td>\n",
       "      <td>27.674742</td>\n",
       "      <td>27.919083</td>\n",
       "      <td>27.505342</td>\n",
       "      <td>27.464750</td>\n",
       "      <td>27.245262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-11-26</td>\n",
       "      <td>27.674742</td>\n",
       "      <td>27.919083</td>\n",
       "      <td>27.505342</td>\n",
       "      <td>27.464750</td>\n",
       "      <td>27.862717</td>\n",
       "      <td>28.109835</td>\n",
       "      <td>27.697153</td>\n",
       "      <td>27.646967</td>\n",
       "      <td>27.716011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>27.862717</td>\n",
       "      <td>28.109835</td>\n",
       "      <td>27.697153</td>\n",
       "      <td>27.646967</td>\n",
       "      <td>27.976152</td>\n",
       "      <td>28.224979</td>\n",
       "      <td>27.812967</td>\n",
       "      <td>27.756863</td>\n",
       "      <td>27.392220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-11-28</td>\n",
       "      <td>27.976152</td>\n",
       "      <td>28.224979</td>\n",
       "      <td>27.812967</td>\n",
       "      <td>27.756863</td>\n",
       "      <td>28.164940</td>\n",
       "      <td>28.416626</td>\n",
       "      <td>28.005726</td>\n",
       "      <td>27.939831</td>\n",
       "      <td>27.915163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-11-29</td>\n",
       "      <td>28.164940</td>\n",
       "      <td>28.416626</td>\n",
       "      <td>28.005726</td>\n",
       "      <td>27.939831</td>\n",
       "      <td>28.255846</td>\n",
       "      <td>28.508932</td>\n",
       "      <td>28.098593</td>\n",
       "      <td>28.027853</td>\n",
       "      <td>27.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>28.255846</td>\n",
       "      <td>28.508932</td>\n",
       "      <td>28.098593</td>\n",
       "      <td>28.027853</td>\n",
       "      <td>28.428865</td>\n",
       "      <td>28.684628</td>\n",
       "      <td>28.275339</td>\n",
       "      <td>28.195503</td>\n",
       "      <td>28.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>28.428865</td>\n",
       "      <td>28.684628</td>\n",
       "      <td>28.275339</td>\n",
       "      <td>28.195503</td>\n",
       "      <td>28.484921</td>\n",
       "      <td>28.741562</td>\n",
       "      <td>28.332649</td>\n",
       "      <td>28.249744</td>\n",
       "      <td>27.412437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>28.484921</td>\n",
       "      <td>28.741562</td>\n",
       "      <td>28.332649</td>\n",
       "      <td>28.249744</td>\n",
       "      <td>28.617277</td>\n",
       "      <td>28.875996</td>\n",
       "      <td>28.467907</td>\n",
       "      <td>28.377977</td>\n",
       "      <td>27.905846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>28.617277</td>\n",
       "      <td>28.875996</td>\n",
       "      <td>28.467907</td>\n",
       "      <td>28.377977</td>\n",
       "      <td>28.628641</td>\n",
       "      <td>28.887545</td>\n",
       "      <td>28.479544</td>\n",
       "      <td>28.388926</td>\n",
       "      <td>27.266966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>28.628641</td>\n",
       "      <td>28.887545</td>\n",
       "      <td>28.479544</td>\n",
       "      <td>28.388926</td>\n",
       "      <td>28.698395</td>\n",
       "      <td>28.958403</td>\n",
       "      <td>28.550842</td>\n",
       "      <td>28.456507</td>\n",
       "      <td>27.624292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>28.698395</td>\n",
       "      <td>28.958403</td>\n",
       "      <td>28.550842</td>\n",
       "      <td>28.456507</td>\n",
       "      <td>28.646389</td>\n",
       "      <td>28.905579</td>\n",
       "      <td>28.497702</td>\n",
       "      <td>28.406086</td>\n",
       "      <td>26.940062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-12-06</td>\n",
       "      <td>28.646389</td>\n",
       "      <td>28.905579</td>\n",
       "      <td>28.497702</td>\n",
       "      <td>28.406086</td>\n",
       "      <td>28.625792</td>\n",
       "      <td>28.884651</td>\n",
       "      <td>28.476639</td>\n",
       "      <td>28.386148</td>\n",
       "      <td>27.094456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>28.625792</td>\n",
       "      <td>28.884651</td>\n",
       "      <td>28.476639</td>\n",
       "      <td>28.386148</td>\n",
       "      <td>28.500864</td>\n",
       "      <td>28.757761</td>\n",
       "      <td>28.348955</td>\n",
       "      <td>28.265093</td>\n",
       "      <td>26.382061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>28.500864</td>\n",
       "      <td>28.757761</td>\n",
       "      <td>28.348955</td>\n",
       "      <td>28.265093</td>\n",
       "      <td>28.380823</td>\n",
       "      <td>28.635849</td>\n",
       "      <td>28.226297</td>\n",
       "      <td>28.148819</td>\n",
       "      <td>26.335146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>28.380823</td>\n",
       "      <td>28.635849</td>\n",
       "      <td>28.226297</td>\n",
       "      <td>28.148819</td>\n",
       "      <td>28.232111</td>\n",
       "      <td>28.484989</td>\n",
       "      <td>28.074810</td>\n",
       "      <td>28.005106</td>\n",
       "      <td>25.624229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>28.232111</td>\n",
       "      <td>28.484989</td>\n",
       "      <td>28.074810</td>\n",
       "      <td>28.005106</td>\n",
       "      <td>28.088825</td>\n",
       "      <td>28.339544</td>\n",
       "      <td>27.928574</td>\n",
       "      <td>27.866364</td>\n",
       "      <td>25.474833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>28.088825</td>\n",
       "      <td>28.339544</td>\n",
       "      <td>27.928574</td>\n",
       "      <td>27.866364</td>\n",
       "      <td>27.949570</td>\n",
       "      <td>28.198372</td>\n",
       "      <td>27.786953</td>\n",
       "      <td>27.731884</td>\n",
       "      <td>24.911392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>27.949570</td>\n",
       "      <td>28.198372</td>\n",
       "      <td>27.786953</td>\n",
       "      <td>27.731884</td>\n",
       "      <td>27.815298</td>\n",
       "      <td>28.062134</td>\n",
       "      <td>27.650013</td>\n",
       "      <td>27.601860</td>\n",
       "      <td>24.746721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>27.815298</td>\n",
       "      <td>28.062134</td>\n",
       "      <td>27.650013</td>\n",
       "      <td>27.601860</td>\n",
       "      <td>27.685879</td>\n",
       "      <td>27.930946</td>\n",
       "      <td>27.518379</td>\n",
       "      <td>27.476793</td>\n",
       "      <td>24.299038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-12-14</td>\n",
       "      <td>27.685879</td>\n",
       "      <td>27.930946</td>\n",
       "      <td>27.518379</td>\n",
       "      <td>27.476793</td>\n",
       "      <td>27.562031</td>\n",
       "      <td>27.805279</td>\n",
       "      <td>27.392031</td>\n",
       "      <td>27.356758</td>\n",
       "      <td>24.244184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>27.562031</td>\n",
       "      <td>27.805279</td>\n",
       "      <td>27.392031</td>\n",
       "      <td>27.356758</td>\n",
       "      <td>27.442709</td>\n",
       "      <td>27.684338</td>\n",
       "      <td>27.270647</td>\n",
       "      <td>27.241367</td>\n",
       "      <td>23.902790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>27.442709</td>\n",
       "      <td>27.684338</td>\n",
       "      <td>27.270647</td>\n",
       "      <td>27.241367</td>\n",
       "      <td>27.328419</td>\n",
       "      <td>27.568403</td>\n",
       "      <td>27.154085</td>\n",
       "      <td>27.130560</td>\n",
       "      <td>23.870874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-12-17</td>\n",
       "      <td>27.328419</td>\n",
       "      <td>27.568403</td>\n",
       "      <td>27.154085</td>\n",
       "      <td>27.130560</td>\n",
       "      <td>27.217314</td>\n",
       "      <td>27.455990</td>\n",
       "      <td>27.041636</td>\n",
       "      <td>27.023548</td>\n",
       "      <td>23.058115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>27.217314</td>\n",
       "      <td>27.455990</td>\n",
       "      <td>27.041636</td>\n",
       "      <td>27.023548</td>\n",
       "      <td>27.111141</td>\n",
       "      <td>27.348307</td>\n",
       "      <td>26.933363</td>\n",
       "      <td>26.920567</td>\n",
       "      <td>23.057726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>27.111141</td>\n",
       "      <td>27.348307</td>\n",
       "      <td>26.933363</td>\n",
       "      <td>26.920567</td>\n",
       "      <td>27.007883</td>\n",
       "      <td>27.243853</td>\n",
       "      <td>26.828871</td>\n",
       "      <td>26.821083</td>\n",
       "      <td>22.326815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>27.007883</td>\n",
       "      <td>27.243853</td>\n",
       "      <td>26.828871</td>\n",
       "      <td>26.821083</td>\n",
       "      <td>26.909086</td>\n",
       "      <td>27.143681</td>\n",
       "      <td>26.728182</td>\n",
       "      <td>26.725256</td>\n",
       "      <td>22.305548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>26.909086</td>\n",
       "      <td>27.143681</td>\n",
       "      <td>26.728182</td>\n",
       "      <td>26.725256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Prev O     Prev H     Prev L     Prev C     Curr O  \\\n",
       "0  2023-11-01  24.510000  24.700001  24.379999  24.570000  24.563128   \n",
       "1  2023-11-02  24.563128  24.768059  24.340754  24.445387  24.564661   \n",
       "2  2023-11-03  24.564661  24.769562  24.342165  24.446774  24.562559   \n",
       "3  2023-11-04  24.562559  24.767447  24.340057  24.444750  24.611757   \n",
       "4  2023-11-05  24.611757  24.817135  24.389843  24.492489  24.642338   \n",
       "5  2023-11-06  24.642338  24.848045  24.420855  24.522184  24.747187   \n",
       "6  2023-11-07  24.747187  24.954016  24.527174  24.624062  24.822468   \n",
       "7  2023-11-08  24.822468  25.030117  24.603537  24.697159  24.983639   \n",
       "8  2023-11-09  24.983639  25.193060  24.767038  24.853722  25.085915   \n",
       "9  2023-11-10  25.085915  25.296484  24.870846  24.953011  25.270473   \n",
       "10 2023-11-11  25.270473  25.483147  25.058182  25.132259  25.393465   \n",
       "11 2023-11-12  25.393465  25.607576  25.183088  25.251644  25.588408   \n",
       "12 2023-11-13  25.588408  25.804831  25.381102  25.440937  25.722607   \n",
       "13 2023-11-14  25.722607  25.940651  25.517475  25.571177  25.921316   \n",
       "14 2023-11-15  25.921316  26.141809  25.719454  25.764082  26.059706   \n",
       "15 2023-11-16  26.059706  26.281940  25.860186  25.898357  26.256159   \n",
       "16 2023-11-17  26.256159  26.480900  26.060005  26.089025  26.394238   \n",
       "17 2023-11-18  26.394238  26.620777  26.200518  26.222973  26.586699   \n",
       "18 2023-11-19  26.586699  26.815779  26.396412  26.409721  26.721920   \n",
       "19 2023-11-20  26.721920  26.952816  26.534107  26.540863  26.913568   \n",
       "20 2023-11-21  26.913568  27.147076  26.729298  26.726774  27.044844   \n",
       "21 2023-11-22  27.044844  27.280170  26.863066  26.854059  27.235376   \n",
       "22 2023-11-23  27.235376  27.473375  27.057247  27.038845  27.362526   \n",
       "23 2023-11-24  27.362526  27.602337  27.186892  27.162096  27.551767   \n",
       "24 2023-11-25  27.551767  27.794308  27.379879  27.345583  27.674742   \n",
       "25 2023-11-26  27.674742  27.919083  27.505342  27.464750  27.862717   \n",
       "26 2023-11-27  27.862717  28.109835  27.697153  27.646967  27.976152   \n",
       "27 2023-11-28  27.976152  28.224979  27.812967  27.756863  28.164940   \n",
       "28 2023-11-29  28.164940  28.416626  28.005726  27.939831  28.255846   \n",
       "29 2023-11-30  28.255846  28.508932  28.098593  28.027853  28.428865   \n",
       "30 2023-12-01  28.428865  28.684628  28.275339  28.195503  28.484921   \n",
       "31 2023-12-02  28.484921  28.741562  28.332649  28.249744  28.617277   \n",
       "32 2023-12-03  28.617277  28.875996  28.467907  28.377977  28.628641   \n",
       "33 2023-12-04  28.628641  28.887545  28.479544  28.388926  28.698395   \n",
       "34 2023-12-05  28.698395  28.958403  28.550842  28.456507  28.646389   \n",
       "35 2023-12-06  28.646389  28.905579  28.497702  28.406086  28.625792   \n",
       "36 2023-12-07  28.625792  28.884651  28.476639  28.386148  28.500864   \n",
       "37 2023-12-08  28.500864  28.757761  28.348955  28.265093  28.380823   \n",
       "38 2023-12-09  28.380823  28.635849  28.226297  28.148819  28.232111   \n",
       "39 2023-12-10  28.232111  28.484989  28.074810  28.005106  28.088825   \n",
       "40 2023-12-11  28.088825  28.339544  27.928574  27.866364  27.949570   \n",
       "41 2023-12-12  27.949570  28.198372  27.786953  27.731884  27.815298   \n",
       "42 2023-12-13  27.815298  28.062134  27.650013  27.601860  27.685879   \n",
       "43 2023-12-14  27.685879  27.930946  27.518379  27.476793  27.562031   \n",
       "44 2023-12-15  27.562031  27.805279  27.392031  27.356758  27.442709   \n",
       "45 2023-12-16  27.442709  27.684338  27.270647  27.241367  27.328419   \n",
       "46 2023-12-17  27.328419  27.568403  27.154085  27.130560  27.217314   \n",
       "47 2023-12-18  27.217314  27.455990  27.041636  27.023548  27.111141   \n",
       "48 2023-12-19  27.111141  27.348307  26.933363  26.920567  27.007883   \n",
       "49 2023-12-20  27.007883  27.243853  26.828871  26.821083  26.909086   \n",
       "50 2023-12-21  26.909086  27.143681  26.728182  26.725256   0.000000   \n",
       "\n",
       "       Curr H     Curr L     Curr C  Sim Adj Close  \n",
       "0   24.768059  24.340754  24.445387      24.333868  \n",
       "1   24.769562  24.342165  24.446774      24.594799  \n",
       "2   24.767447  24.340057  24.444750      24.555912  \n",
       "3   24.817135  24.389843  24.492489      24.931833  \n",
       "4   24.848045  24.420855  24.522184      24.851326  \n",
       "5   24.954016  24.527174  24.624062      25.307402  \n",
       "6   25.030117  24.603537  24.697159      25.195097  \n",
       "7   25.193060  24.767038  24.853722      25.747158  \n",
       "8   25.296484  24.870846  24.953011      25.495913  \n",
       "9   25.483147  25.058182  25.132259      26.044176  \n",
       "10  25.607576  25.183088  25.251644      25.792072  \n",
       "11  25.804831  25.381102  25.440937      26.293468  \n",
       "12  25.940651  25.517475  25.571177      26.053547  \n",
       "13  26.141809  25.719454  25.764082      26.519480  \n",
       "14  26.281940  25.860186  25.898357      26.285475  \n",
       "15  26.480900  26.060005  26.089025      26.717447  \n",
       "16  26.620777  26.200518  26.222973      26.494652  \n",
       "17  26.815779  26.396412  26.409721      26.906139  \n",
       "18  26.952816  26.534107  26.540863      26.688526  \n",
       "19  27.147076  26.729298  26.726774      27.111891  \n",
       "20  27.280170  26.863066  26.854059      26.876041  \n",
       "21  27.473375  27.057247  27.038845      27.315159  \n",
       "22  27.602337  27.186892  27.162096      27.061474  \n",
       "23  27.794308  27.379879  27.345583      27.516254  \n",
       "24  27.919083  27.505342  27.464750      27.245262  \n",
       "25  28.109835  27.697153  27.646967      27.716011  \n",
       "26  28.224979  27.812967  27.756863      27.392220  \n",
       "27  28.416626  28.005726  27.939831      27.915163  \n",
       "28  28.508932  28.098593  28.027853      27.450800  \n",
       "29  28.684628  28.275339  28.195503      28.000847  \n",
       "30  28.741562  28.332649  28.249744      27.412437  \n",
       "31  28.875996  28.467907  28.377977      27.905846  \n",
       "32  28.887545  28.479544  28.388926      27.266966  \n",
       "33  28.958403  28.550842  28.456507      27.624292  \n",
       "34  28.905579  28.497702  28.406086      26.940062  \n",
       "35  28.884651  28.476639  28.386148      27.094456  \n",
       "36  28.757761  28.348955  28.265093      26.382061  \n",
       "37  28.635849  28.226297  28.148819      26.335146  \n",
       "38  28.484989  28.074810  28.005106      25.624229  \n",
       "39  28.339544  27.928574  27.866364      25.474833  \n",
       "40  28.198372  27.786953  27.731884      24.911392  \n",
       "41  28.062134  27.650013  27.601860      24.746721  \n",
       "42  27.930946  27.518379  27.476793      24.299038  \n",
       "43  27.805279  27.392031  27.356758      24.244184  \n",
       "44  27.684338  27.270647  27.241367      23.902790  \n",
       "45  27.568403  27.154085  27.130560      23.870874  \n",
       "46  27.455990  27.041636  27.023548      23.058115  \n",
       "47  27.348307  26.933363  26.920567      23.057726  \n",
       "48  27.243853  26.828871  26.821083      22.326815  \n",
       "49  27.143681  26.728182  26.725256      22.305548  \n",
       "50   0.000000   0.000000   0.000000       0.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_df.head(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2827238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Overbought</th>\n",
       "      <th>Oversold</th>\n",
       "      <th>Price_RSI_Divergence</th>\n",
       "      <th>ROC_RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_SMA_Difference</th>\n",
       "      <th>Slope_SMA</th>\n",
       "      <th>SMA_Convergence</th>\n",
       "      <th>SMA_Divergence</th>\n",
       "      <th>ROC_SMA</th>\n",
       "      <th>ADX</th>\n",
       "      <th>DMI+</th>\n",
       "      <th>DMI-</th>\n",
       "      <th>ADX_Trend_Strength</th>\n",
       "      <th>DI_Convergence_Divergence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-20</th>\n",
       "      <td>29.200001</td>\n",
       "      <td>29.549999</td>\n",
       "      <td>29.190001</td>\n",
       "      <td>29.510000</td>\n",
       "      <td>19.340019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21</th>\n",
       "      <td>29.510000</td>\n",
       "      <td>29.610001</td>\n",
       "      <td>29.230000</td>\n",
       "      <td>29.230000</td>\n",
       "      <td>19.156521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22</th>\n",
       "      <td>29.430000</td>\n",
       "      <td>29.559999</td>\n",
       "      <td>28.809999</td>\n",
       "      <td>29.520000</td>\n",
       "      <td>19.346575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-23</th>\n",
       "      <td>29.410000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>29.320000</td>\n",
       "      <td>29.540001</td>\n",
       "      <td>19.359678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-24</th>\n",
       "      <td>29.469999</td>\n",
       "      <td>29.490000</td>\n",
       "      <td>29.260000</td>\n",
       "      <td>29.410000</td>\n",
       "      <td>19.274483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-16</th>\n",
       "      <td>27.328419</td>\n",
       "      <td>27.568403</td>\n",
       "      <td>27.154085</td>\n",
       "      <td>27.130560</td>\n",
       "      <td>23.870874</td>\n",
       "      <td>28.463074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079091</td>\n",
       "      <td>-0.662753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759602</td>\n",
       "      <td>-0.089101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.318455</td>\n",
       "      <td>46.016588</td>\n",
       "      <td>10.550752</td>\n",
       "      <td>15.618984</td>\n",
       "      <td>48.268901</td>\n",
       "      <td>-5.068232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-17</th>\n",
       "      <td>27.217314</td>\n",
       "      <td>27.455990</td>\n",
       "      <td>27.041636</td>\n",
       "      <td>27.023548</td>\n",
       "      <td>23.058115</td>\n",
       "      <td>24.085358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.270704</td>\n",
       "      <td>-15.380334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769087</td>\n",
       "      <td>-0.097527</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>44.490692</td>\n",
       "      <td>9.882049</td>\n",
       "      <td>16.349088</td>\n",
       "      <td>46.191285</td>\n",
       "      <td>-6.467038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-18</th>\n",
       "      <td>27.111141</td>\n",
       "      <td>27.348307</td>\n",
       "      <td>26.933363</td>\n",
       "      <td>26.920567</td>\n",
       "      <td>23.057726</td>\n",
       "      <td>24.083449</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.101072</td>\n",
       "      <td>-0.007929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762359</td>\n",
       "      <td>-0.109710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.394745</td>\n",
       "      <td>43.416421</td>\n",
       "      <td>9.249807</td>\n",
       "      <td>16.972513</td>\n",
       "      <td>44.641234</td>\n",
       "      <td>-7.722706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-19</th>\n",
       "      <td>27.007883</td>\n",
       "      <td>27.243853</td>\n",
       "      <td>26.828871</td>\n",
       "      <td>26.821083</td>\n",
       "      <td>22.326815</td>\n",
       "      <td>20.754444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.229521</td>\n",
       "      <td>-13.822792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.748628</td>\n",
       "      <td>-0.113214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.408969</td>\n",
       "      <td>42.731622</td>\n",
       "      <td>8.653521</td>\n",
       "      <td>17.501602</td>\n",
       "      <td>43.546245</td>\n",
       "      <td>-8.848081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20</th>\n",
       "      <td>26.909086</td>\n",
       "      <td>27.143681</td>\n",
       "      <td>26.728182</td>\n",
       "      <td>26.725256</td>\n",
       "      <td>22.305548</td>\n",
       "      <td>20.664937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006321</td>\n",
       "      <td>-0.431265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.725820</td>\n",
       "      <td>-0.118635</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.430310</td>\n",
       "      <td>42.381718</td>\n",
       "      <td>8.091108</td>\n",
       "      <td>17.939109</td>\n",
       "      <td>42.843254</td>\n",
       "      <td>-9.848001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close        RSI  \\\n",
       "Date                                                                           \n",
       "2018-08-20  29.200001  29.549999  29.190001  29.510000  19.340019        NaN   \n",
       "2018-08-21  29.510000  29.610001  29.230000  29.230000  19.156521        NaN   \n",
       "2018-08-22  29.430000  29.559999  28.809999  29.520000  19.346575        NaN   \n",
       "2018-08-23  29.410000  29.540001  29.320000  29.540001  19.359678        NaN   \n",
       "2018-08-24  29.469999  29.490000  29.260000  29.410000  19.274483        NaN   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2023-12-16  27.328419  27.568403  27.154085  27.130560  23.870874  28.463074   \n",
       "2023-12-17  27.217314  27.455990  27.041636  27.023548  23.058115  24.085358   \n",
       "2023-12-18  27.111141  27.348307  26.933363  26.920567  23.057726  24.083449   \n",
       "2023-12-19  27.007883  27.243853  26.828871  26.821083  22.326815  20.754444   \n",
       "2023-12-20  26.909086  27.143681  26.728182  26.725256  22.305548  20.664937   \n",
       "\n",
       "            Overbought  Oversold  Price_RSI_Divergence    ROC_RSI  ...  \\\n",
       "Date                                                               ...   \n",
       "2018-08-20           0         0                   NaN        NaN  ...   \n",
       "2018-08-21           0         0                   NaN        NaN  ...   \n",
       "2018-08-22           0         0                   NaN        NaN  ...   \n",
       "2018-08-23           0         0                   NaN        NaN  ...   \n",
       "2018-08-24           0         0                   NaN        NaN  ...   \n",
       "...                ...       ...                   ...        ...  ...   \n",
       "2023-12-16           0         1              0.079091  -0.662753  ...   \n",
       "2023-12-17           0         1              4.270704 -15.380334  ...   \n",
       "2023-12-18           0         1             -0.101072  -0.007929  ...   \n",
       "2023-12-19           0         1              3.229521 -13.822792  ...   \n",
       "2023-12-20           0         1             -0.006321  -0.431265  ...   \n",
       "\n",
       "            Price_SMA_Difference  Slope_SMA  SMA_Convergence  SMA_Divergence  \\\n",
       "Date                                                                           \n",
       "2018-08-20                   NaN        NaN                0               0   \n",
       "2018-08-21                   NaN        NaN                0               0   \n",
       "2018-08-22                   NaN        NaN                0               0   \n",
       "2018-08-23                   NaN        NaN                0               0   \n",
       "2018-08-24                   NaN        NaN                0               0   \n",
       "...                          ...        ...              ...             ...   \n",
       "2023-12-16             -0.759602  -0.089101                0               1   \n",
       "2023-12-17             -0.769087  -0.097527                0               1   \n",
       "2023-12-18             -0.762359  -0.109710                0               1   \n",
       "2023-12-19             -0.748628  -0.113214                0               1   \n",
       "2023-12-20             -0.725820  -0.118635                0               1   \n",
       "\n",
       "             ROC_SMA        ADX       DMI+       DMI-  ADX_Trend_Strength  \\\n",
       "Date                                                                        \n",
       "2018-08-20       NaN        NaN        NaN        NaN                 NaN   \n",
       "2018-08-21       NaN        NaN        NaN        NaN                 NaN   \n",
       "2018-08-22       NaN        NaN        NaN        NaN                 NaN   \n",
       "2018-08-23       NaN        NaN        NaN        NaN                 NaN   \n",
       "2018-08-24       NaN        NaN        NaN        NaN                 NaN   \n",
       "...              ...        ...        ...        ...                 ...   \n",
       "2023-12-16 -0.318455  46.016588  10.550752  15.618984           48.268901   \n",
       "2023-12-17 -0.349682  44.490692   9.882049  16.349088           46.191285   \n",
       "2023-12-18 -0.394745  43.416421   9.249807  16.972513           44.641234   \n",
       "2023-12-19 -0.408969  42.731622   8.653521  17.501602           43.546245   \n",
       "2023-12-20 -0.430310  42.381718   8.091108  17.939109           42.843254   \n",
       "\n",
       "            DI_Convergence_Divergence  \n",
       "Date                                   \n",
       "2018-08-20                        NaN  \n",
       "2018-08-21                        NaN  \n",
       "2018-08-22                        NaN  \n",
       "2018-08-23                        NaN  \n",
       "2018-08-24                        NaN  \n",
       "...                               ...  \n",
       "2023-12-16                  -5.068232  \n",
       "2023-12-17                  -6.467038  \n",
       "2023-12-18                  -7.722706  \n",
       "2023-12-19                  -8.848081  \n",
       "2023-12-20                  -9.848001  \n",
       "\n",
       "[1359 rows x 28 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054197e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
